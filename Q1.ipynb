{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "QdpJDowTMzAw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from samplers import *\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        _layers = []\n",
        "        for i, _ in enumerate(layers[:-1]):\n",
        "            _layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
        "            if i != len(layers) - 2:\n",
        "                _layers.append(nn.ReLU())\n",
        "            else:\n",
        "                self._add_last_layer(_layers)\n",
        "                pass\n",
        "        self.layers = nn.Sequential(*_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "    def _add_last_layer(self, layers):\n",
        "        raise NotImplementedError  # add sigmoid if JSD is used\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Shp74WyMM5YK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Q1.1"
      ]
    },
    {
      "metadata": {
        "id": "5aIE2j_fM4pa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class JSDiscriminator(Discriminator):\n",
        "\n",
        "    def loss(self, inputs, outputs, targets):\n",
        "        value = torch.log(torch.tensor(2., device=device)) + 0.5 * (\n",
        "                torch.log(outputs[targets == 1.]).mean() + torch.log(1. - outputs[targets == 0.]).mean())\n",
        "        return -value, None, None\n",
        "\n",
        "    def _add_last_layer(self, layers):\n",
        "        layers.append(nn.Sigmoid())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ufSSe1BM9Au",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Q1.2"
      ]
    },
    {
      "metadata": {
        "id": "DVG-XvupM-KR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class WDiscriminator(Discriminator):\n",
        "    _lambda = 10\n",
        "\n",
        "    def loss(self, inputs, outputs, targets):\n",
        "        gp = self._compute_gp(inputs, targets)\n",
        "        value1 = outputs[targets == 1.].mean() - outputs[targets == 0.].mean()\n",
        "        value2 = WDiscriminator._lambda * ((gp - 1.) ** 2).mean()\n",
        "        value = value1 - value2\n",
        "        return -value, -value1, value2\n",
        "\n",
        "    def _add_last_layer(self, layers):\n",
        "        pass\n",
        "\n",
        "    def _compute_gp(self, inputs, targets):\n",
        "        real_data = inputs[targets == 1.]\n",
        "        fake_data = inputs[targets == 0.]\n",
        "\n",
        "        fracs = torch.rand(len(real_data), 1).to(device)\n",
        "        interpolated = fracs * real_data + (1. - fracs) * fake_data\n",
        "        interpolated.requires_grad_()\n",
        "        value = self(interpolated).sum()\n",
        "        value.backward(create_graph=True)\n",
        "        value = interpolated.grad.norm(p=2, dim=1)\n",
        "        return value\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8bP6trEXNDby",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Q1.3"
      ]
    },
    {
      "metadata": {
        "id": "F67EeGeDM_3W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Question 1.1\n",
        "device = 'cpu'\n",
        "N_ITERS = 10000\n",
        "# phi = 1.\n",
        "# variant = 'JSD'\n",
        "\n",
        "for phi in np.arange(-1., 1.1, 0.1):\n",
        "    phi = 0.1\n",
        "    for variant in ['JSD', 'EMD']:\n",
        "        if variant == 'JSD':\n",
        "            discriminator = JSDiscriminator([2, 512, 512, 512, 1]).to(device)\n",
        "        else:\n",
        "            discriminator = WDiscriminator([2, 512, 512, 512, 1]).to(device)\n",
        "        optimizer = optim.SGD(discriminator.parameters(), lr=1e-3)\n",
        "        for itr, real_data, fake_data in zip(range(N_ITERS), distribution1(0.), distribution1(phi)):\n",
        "            data = torch.cat([torch.tensor(real_data, dtype=torch.float), torch.tensor(fake_data, dtype=torch.float)],\n",
        "                             dim=0).to(device)\n",
        "            targets = torch.cat([torch.ones(len(real_data), dtype=torch.uint8), torch.zeros(len(fake_data), dtype=torch.uint8)]).to(device)\n",
        "            outputs = discriminator(data)\n",
        "\n",
        "            loss = discriminator.loss(data, outputs, targets)\n",
        "            if itr + 1 == N_ITERS or itr % 100 == 0:\n",
        "                # print('itr: {} loss: {} auxiliary1: {} auxiliary2: {}'.format(itr, loss[0].detach().cpu(),\n",
        "                #                                                               None if not loss[1] else loss[1].detach().cpu(),\n",
        "                #                                                               None if not loss[2] else loss[2].detach().cpu()))\n",
        "                if variant == 'JSD':\n",
        "                    distance = abs(loss[0].detach().cpu())\n",
        "                else:\n",
        "                    distance = abs(loss[1].detach().cpu())\n",
        "                print('{} {} {}'.format(variant, phi, distance))\n",
        "                with open(\"a3.out\", \"a\") as myfile:\n",
        "                    myfile.write('{} {} {}\\n'.format(variant, phi, distance))\n",
        "                print('outputs: ', outputs)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss[0].backward()\n",
        "            optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_W9iyaoRNYZa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Q1.4"
      ]
    },
    {
      "metadata": {
        "id": "UyLTe7ddNw95",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the discriminator\n",
        "device = 'cpu'\n",
        "discriminator = JSDiscriminator([1, 256, 256, 256, 1]).to(device)\n",
        "optimizer = optim.SGD(discriminator.parameters(), lr=1e-3)\n",
        "for itr, real_data, fake_data in zip(range(40000), distribution4(), distribution3()):\n",
        "    data = torch.cat([torch.tensor(real_data, dtype=torch.float), torch.tensor(fake_data, dtype=torch.float)],\n",
        "                     dim=0).to(device)\n",
        "    targets = torch.cat(\n",
        "        [torch.ones(len(real_data), dtype=torch.uint8), torch.zeros(len(fake_data), dtype=torch.uint8)]).to(device)\n",
        "    outputs = discriminator(data)\n",
        "\n",
        "    loss = discriminator.loss(data, outputs, targets)\n",
        "    optimizer.zero_grad()\n",
        "    loss[0].backward()\n",
        "    optimizer.step()\n",
        "    if itr % 500 == 0:\n",
        "        print('loss: {} outputs: {} itr: {} '.format(loss, (outputs[:10], outputs[-10:]), itr))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############### plotting things\n",
        "############### (1) plot the output of your trained discriminator \n",
        "############### (2) plot the estimated density contrasted with the true density\n",
        "\n",
        "\n",
        "r = discriminator(torch.tensor(xx, device=device, dtype=torch.float).view(-1, 1)).detach().cpu().numpy() # evaluate xx using your discriminator; replace xx with the output\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(xx,r)\n",
        "plt.title(r'$D(x)$')\n",
        "\n",
        "temp = N(xx)\n",
        "estimate = temp.reshape(*r.shape) * r/(1. - r)#np.ones_like(xx)*0.2 # estimate the density of distribution4 (on xx) using the discriminator;\n",
        "                                # replace \"np.ones_like(xx)*0.\" with your estimate\n",
        "print('d-shape: {} r-shape: {} r-over-shape: {} estimate-shape: {}'.format(temp.shape, r.shape, (r/(1. - r)).shape,\n",
        "                                                                           (temp.reshape(*r.shape) * r/(1. - r)).shape))\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(xx,estimate)\n",
        "plt.plot(f(torch.from_numpy(xx)).numpy(), d(torch.from_numpy(xx)).numpy()**(-1)*N(xx))\n",
        "plt.legend(['Estimated','True'])\n",
        "plt.title('Estimated vs True')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0e4GczCjN5w9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}